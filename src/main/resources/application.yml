#spring:
#  datasource:
#    url: jdbc:postgresql://localhost:5432/batchdb
#    username: batchuser
#    password: batchpass
#    driver-class-name: org.postgresql.Driver
#
#  jpa:
#    hibernate:
#      ddl-auto: none
#
#  batch:
#    initialize-schema: always
spring:
  application:
    name: spring-batch-probe
  profiles:
    active: ${SPRING_PROFILES_ACTIVE:dev}
  batch:
    job:
      enabled: true
    # This is now handled by spring.sql.init.mode below
    initialize-schema: never
  datasource:
    url: ${SPRING_DATASOURCE_URL:jdbc:postgresql://${DB_HOST:localhost}:${DB_PORT:5433}/${DB_NAME:batchdb}}
    username: ${SPRING_DATASOURCE_USERNAME:postgres}
    password: ${SPRING_DATASOURCE_PASSWORD:postgres}
    driver-class-name: org.postgresql.Driver
    hikari:
      # Disable fail-fast so the application doesn't crash immediately when DB isn't ready
      initialization-fail-timeout: ${SPRING_DATASOURCE_HIKARI_INITIALIZATION_FAIL_TIMEOUT:-1}
      # Make validation conservative for containerized environments
      validation-timeout: ${SPRING_DATASOURCE_HIKARI_VALIDATION_TIMEOUT:3000}
      connection-timeout: ${SPRING_DATASOURCE_HIKARI_CONNECTION_TIMEOUT:30000}
  # Use modern SQL initialization to explicitly create all required tables
  sql:
    init:
      mode: embedded
      schema-locations: classpath:db/spring-batch-schema-postgres.sql,classpath:db/schema.sql

server:
  port: ${SERVER_PORT:8080}

management:
  endpoints:
    web:
      exposure:
        include: health,info,prometheus
  endpoint:
    health:
      show-details: always
  metrics:
    export:
      prometheus:
        enabled: true

# Batch configuration
chunk.size: ${CHUNK_SIZE:100}
partition.grid: ${PARTITION_GRID:4}
input.file: ${INPUT_FILE:data/sample-10k.csv}
exit.on.complete: ${EXIT_ON_COMPLETE:false}

logging:
  level:
    com.mayank.batch: INFO
    org.springframework.batch: INFO
    org.springframework.jdbc: WARN
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss} [%thread] %-5level %logger{36} - %msg%n"
